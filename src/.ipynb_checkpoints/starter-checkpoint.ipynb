{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e11f57e-8bff-4ab8-9832-e94036bd3d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/s328743/.conda/envs/bertopic_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "import sqlite3\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088c1c43-7dbb-40ec-a7ee-35d7b2e24be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA PORTATILE SCOMMENTARE QUESTO\n",
    "#extracted_dir = os.path.join(\"..\", \"material\", \"extracted\")\n",
    "\n",
    "#------------------------------------------------\n",
    "#DA JUPYTER CUSTER SCOMMENTARE QUESTO\n",
    "extracted_dir = os.path.expanduser(\"~/telegram_2024/usc-tg-24-us-election/extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81529a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Tabelle nel DB: [('chats',)]\n",
      "‚úÖ chats.db - Tabella 'chats'\n",
      "  type_and_id                            token parent     timestamp\n",
      "0        None           [keyword] thedemocrats   None  1.722583e+09\n",
      "1        None  [keyword] makeamericagreatagain   None  1.722583e+09\n",
      "2        None                   [keyword] MAGA   None  1.722583e+09\n",
      "3        None            [keyword] Nikki Haley   None  1.722583e+09\n",
      "4        None  [keyword] Robert F. Kennedy Jr.   None  1.722583e+09\n",
      "‚úÖ discovery_edges.csv.gz, \n",
      "Il timestamp da l'ultima volta che hanno visitato quel gruppo ma questo significa che non √® davvero indicativo di una timeline \n",
      "\n",
      "          type_and_id              parent     timestamp\n",
      "0  channel_1306559115  channel_1840578235  1.722586e+09\n",
      "1  channel_2036850729  channel_1840578235  1.722586e+09\n",
      "2  channel_1941222046  channel_1840578235  1.722586e+09\n",
      "3  channel_1749991917  channel_1840578235  1.722586e+09\n",
      "4  channel_1581117699  channel_1840578235  1.722586e+09\n",
      "‚úÖ first_nodes.csv.gz\n",
      "          type_and_id                    token                      parent\n",
      "0  channel_2036421633               trump2024e         [keyword] Trump2024\n",
      "1  channel_2178554925  biden_has_left_the_chat             [keyword] Biden\n",
      "2  channel_2095394414             speech_biden      [keyword] Joseph Biden\n",
      "3  channel_2202860593       republicanpartyeth  [keyword] Republican party\n",
      "4  channel_2157448164      republican_partysol  [keyword] Republican party\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "chats_path = '../material/chats.db'\n",
    "conn = sqlite3.connect(chats_path)\n",
    "cursor=conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables=cursor.fetchall()\n",
    "\n",
    "# ========================\n",
    "# 1. Leggi chats.db (SQLite)\n",
    "# ========================\n",
    "\n",
    "print(\"üìå Tabelle nel DB:\", tables)\n",
    "\n",
    "try:\n",
    "    df_chats = pd.read_sql_query(\"SELECT * FROM chats\", conn)\n",
    "    print(\"‚úÖ chats.db - Tabella 'chats'\")\n",
    "    print(df_chats.head())\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Errore nel leggere la tabella:\", e)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# ========================\n",
    "# 2. Leggi discovery_edges.csv.gz\n",
    "# ========================\n",
    "try:\n",
    "    df_edges = pd.read_csv('../material/discovery_edges.csv.gz')\n",
    "    print(\"‚úÖ discovery_edges.csv.gz, \\n\" \\\n",
    "    \"Il timestamp da l'ultima volta che hanno visitato quel gruppo ma questo significa che non √® davvero indicativo di una timeline \\n\")\n",
    "    print(df_edges.head())\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Errore nel leggere discovery_edges:\", e)\n",
    "\n",
    "# ========================\n",
    "# 3. Leggi first_nodes.csv.gz\n",
    "# ========================\n",
    "try:\n",
    "    df_first_nodes = pd.read_csv('../material/first_nodes.csv.gz')\n",
    "    print(\"‚úÖ first_nodes.csv.gz\")\n",
    "    print(df_first_nodes.head())\n",
    "    print(len(df_first_nodes))\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Errore nel leggere first_nodes:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96252cbe-94cd-43b4-90ef-94bf1d01e071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_and_id unique in df_first_nodes247\n",
      "type_and_id in df_first_nodes284\n",
      "type_and_id NaN in df_first_nodes 0\n"
     ]
    }
   ],
   "source": [
    "print(\"type_and_id unique in df_first_nodes\" + str(df_first_nodes.type_and_id.nunique()))\n",
    "print(\"type_and_id in df_first_nodes\" + str(len(df_first_nodes)))\n",
    "print(\"type_and_id NaN in df_first_nodes \" + str(df_first_nodes['type_and_id'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c54587e-fd42-4a59-a107-a66ec8416234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fare preprocessing dei testi:\n",
    "import os\n",
    "import re\n",
    "from typing import Callable, Union\n",
    "\n",
    "# import spacy\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "import langdetect\n",
    "\n",
    "\n",
    "class PreProcessing:\n",
    "    \"\"\"Class for performing text preprocessing operations.\n",
    "\n",
    "    Args:\n",
    "        noadverbs (bool, optional): Flag to remove adverbs from the text. Defaults to False.\n",
    "        noadjectives (bool, optional): Flag to remove adjectives from the text. Defaults to False.\n",
    "        noverbs (bool, optional): Flag to remove verbs from the text. Defaults to False.\n",
    "        noentities (bool, optional): Flag to remove named entities from the text. Defaults to False.\n",
    "        language (str, optional): Language for the Spacy model. Defaults to 'en'.\n",
    "        remove_list (bool, optional): Flag to remove a list of words from the text. Defaults to False.\n",
    "\n",
    "    Attributes:\n",
    "        noadverbs (bool): Flag to remove adverbs from the text.\n",
    "        noadjectives (bool): Flag to remove adjectives from the text.\n",
    "        noverbs (bool): Flag to remove verbs from the text.\n",
    "        noentities (bool): Flag to remove named entities from the text.\n",
    "        language (str): Language for the Spacy model.\n",
    "        remove_list (bool): Flag to remove a list of words from the text.\n",
    "        punctuation (str): Regular expression pattern for removing punctuation.\n",
    "        nlp (spacy.Language): Spacy language model.\n",
    "        stopwords (list): List of stopwords.\n",
    "\n",
    "    Methods:\n",
    "        lowercase_unidecode: Converts text to lowercase and removes diacritics.\n",
    "        remove_urls: Removes URLs from the text.\n",
    "        remove_tweet_marking: Removes Twitter mentions and hashtags from the text.\n",
    "        remove_punctuation: Removes punctuation from the text.\n",
    "        remove_repetion: Removes repeated words from the text.\n",
    "        append_stopwords_list: Appends additional stopwords to the existing list.\n",
    "        remove_stopwords: Removes stopwords from the text.\n",
    "        remove_n: Removes words with length less than or equal to n from the text.\n",
    "        remove_numbers: Removes or filters out numbers from the text.\n",
    "        remove_gerund: Removes gerund endings from verbs in the text.\n",
    "        remove_infinitive: Removes infinitive endings from verbs in the text.\n",
    "        filter_by_idf: Filters out words based on their inverse document frequency.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, noadverbs: bool = False, noadjectives: bool = False, noverbs: bool = False,\n",
    "                 noentities: bool = False, language: str = 'en', remove_list: bool = False,stopwords=[]):\n",
    "        \"\"\"Initialize the PreProcessing object.\n",
    "\n",
    "        Args:\n",
    "            noadverbs (bool, optional): Flag to indicate whether to remove adverbs. Defaults to False.\n",
    "            noadjectives (bool, optional): Flag to indicate whether to remove adjectives. Defaults to False.\n",
    "            noverbs (bool, optional): Flag to indicate whether to remove verbs. Defaults to False.\n",
    "            noentities (bool, optional): Flag to indicate whether to remove named entities. Defaults to False.\n",
    "            remove_list (bool, optional): Flag to indicate whether to remove stopwords. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.noadverbs = noadverbs\n",
    "        self.noadjectives = noadjectives\n",
    "        self.noverbs = noverbs\n",
    "        self.noentities = noentities\n",
    "        self.remove_list = remove_list\n",
    "        self.punctuation = (\n",
    "                r'\\(|!|\"|#|\\$|%|&|\\'|\\(|\\)|\\*|\\+|,|-|\\.|\\/|'\n",
    "                r':|;|<|=|>|\\?|\\@|\\[|\\]|\\^|_|`|\\{|\\}|~|\\||'\n",
    "                r'\\r\\n|\\n|\\r|\\\\\\)'\n",
    "        )\n",
    "        # self.nlp = self._load_spacy_model(language)\n",
    "        # self.stopwords = [unidecode(x).lower() for x in list(self.nlp.Defaults.stop_words)]\n",
    "        self.stopwords=stopwords\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def _process_text(self, text: Union[str, list], function: Callable) -> Union[str, list]:\n",
    "\n",
    "        if isinstance(text, str):\n",
    "            return function(text)\n",
    "        elif isinstance(text, list):\n",
    "            return [function(x) for x in text]\n",
    "        return ''\n",
    "    \n",
    "    \n",
    "    def lowercase_unidecode(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Convert the given text to lowercase and remove any diacritical marks (accents).\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The text to be processed. It can be either a string or a list of strings.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text. If the input is a string, the output will be a string. If the input is a list,\n",
    "            the output will be a list of strings.\n",
    "\n",
    "        Example:\n",
    "            >>> pre_processor = PreProcessor()\n",
    "            >>> text = \"Caf√©\"\n",
    "            >>> pre_processor.lowercase_unidecode(text)\n",
    "            'cafe'\n",
    "        \"\"\"\n",
    "        from unidecode import unidecode\n",
    "        text = self._process_text(text, lambda value: value.lower())\n",
    "        text = self._process_text(text, unidecode)\n",
    "        return text\n",
    "\n",
    "    def remove_urls(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Removes URLs from the given text or list of texts.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The text or list of texts from which to remove URLs.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The text or list of texts with URLs removed.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._process_text(text, lambda value: re.sub(r'http\\S+ *', '', value).strip())\n",
    "\n",
    "    def remove_tweet_marking(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Removes tweet markings (e.g., @mentions and #hashtags) from the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The text or list of texts to process.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text or list of processed texts with tweet markings removed.\n",
    "        \"\"\"\n",
    "        return self._process_text(text, lambda value: re.sub(r'(@|#)\\S+ *', '', value).strip())\n",
    "\n",
    "    def remove_html_tags(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Removes HTML tags from the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The text or list of texts to process.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text or list of processed texts with HTML tags removed.\n",
    "        \"\"\"\n",
    "        return self._process_text(text, lambda value: re.sub(r'<.*?> *', '', value).strip())\n",
    "\n",
    "    def remove_punctuation(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Removes punctuation from the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The text from which punctuation needs to be removed.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The text with punctuation removed.\n",
    "        \"\"\"\n",
    "        text = self._process_text(text, lambda value: re.sub(self.punctuation, ' ', value))\n",
    "        text = self._process_text(text, lambda value: re.sub(' {2,}', ' ', value).strip())\n",
    "        return text\n",
    "\n",
    "    def remove_repetition(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Removes repeated words in the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The input text or list of words.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text with repeated words removed.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._process_text(text, lambda value: re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', value))\n",
    "\n",
    "    def append_stopwords_list(self, stopwords: list) -> None:\n",
    "        \"\"\"Appends additional stopwords to the existing list of stopwords.\n",
    "\n",
    "        Parameters:\n",
    "        stopwords (list): A list of stopwords to be appended.\n",
    "\n",
    "        \"\"\"\n",
    "        self.stopwords.extend(stopwords)\n",
    "\n",
    "    def remove_stopwords(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Removes stopwords from the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The input text from which stopwords need to be removed.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text with stopwords removed.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._process_text(text, lambda value: re.sub(rf'\\b({\"|\".join(self.stopwords)})\\b *', '', value).strip())\n",
    "\n",
    "    \n",
    "\n",
    "    def remove_n(self, text: Union[str, list], n: int) -> Union[str, list]:\n",
    "        \"\"\"Removes words of length 1 to n followed by the word 'pri' from the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The input text or list of texts to process.\n",
    "            n (int): The maximum length of words to remove.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text or list of processed texts.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._process_text(text, lambda value: re.sub(rf'(\\b|^)\\w{{1,{n}}}(\\b|$) ?', '', value).strip())\n",
    "\n",
    "    def remove_numbers(self, text: Union[str, list], mode: str = 'replace') -> Union[str, list]:\n",
    "        \"\"\"Removes or replaces numbers in the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The input text or list of texts.\n",
    "            mode (str, optional): The mode of operation. Defaults to 'replace'.\n",
    "                - 'filter': Removes the numbers from the text.\n",
    "                - 'replace': Replaces the numbers with an empty string.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text or list of processed texts.\n",
    "        \"\"\"\n",
    "        if mode == \"filter\":\n",
    "            return self._process_text(text, lambda value: '' if re.search('[0-9]', value) else value)\n",
    "        elif mode == \"replace\":\n",
    "            return self._process_text(text, lambda value: re.sub('[0-9] *', '', value))\n",
    "\n",
    "    def remove_gerund(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Removes the gerund form '-ndo' from the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The input text or list of texts to process.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text with the gerund form removed.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._process_text(text, lambda value: re.sub(r'ndo\\b', '', value))\n",
    "\n",
    "    def remove_infinitive(self, text: Union[str, list]) -> Union[str, list]:\n",
    "        \"\"\"Removes the infinitive form of verbs from the given text.\n",
    "\n",
    "        Args:\n",
    "            text (Union[str, list]): The input text or list of texts to process.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, list]: The processed text with infinitive forms removed.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._process_text(text, lambda value: re.sub(r'r\\b', '', value))\n",
    "    \n",
    "    \n",
    "    def detect_language(self,text):\n",
    "        import langdetect\n",
    "        try:\n",
    "            d=langdetect.detect_langs(text)\n",
    "            # Trasforma la lista in un dizionario\n",
    "            langs_dict = {lang.lang: lang.prob for lang in d}\n",
    "            best_lang=max(langs_dict,key=langs_dict.get)\n",
    "            best_lang=best_lang if langs_dict[best_lang]>=0.7 else 'unk'\n",
    "            return best_lang    \n",
    "        except langdetect.LangDetectException as e:\n",
    "            return 'unk'\n",
    "        return None\n",
    "\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords = list(STOP_WORDS)\n",
    "\n",
    "# here the funziona to call to preprocess the text\n",
    "def preprocess_text(text,stopwords=stopwords):\n",
    "    \n",
    "    pp=PreProcessing(language='en',stopwords=stopwords)\n",
    "    \n",
    "    # Preprocessing pipeline\n",
    "    text = pp.lowercase_unidecode(text)\n",
    "    \n",
    "    if pp.detect_language(text)!='en':\n",
    "        return \"\"\n",
    "    \n",
    "    text = pp.remove_stopwords(text)\n",
    "    text = pp.remove_tweet_marking(text)\n",
    "    text = pp.remove_urls(text)\n",
    "    text = pp.remove_repetition(text)\n",
    "    text = pp.remove_punctuation(text)\n",
    "    text = pp.remove_numbers(text)\n",
    "    text = pp.remove_n(text, n=3)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36007e0f-c877-4c45-b66b-0b3708e6db5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è  File non trovato, procedo con il preprocessing...\n",
      "len(df_first_nodes) 284\n",
      "print(df_first_nodes.type_and_id.nunique()) 247\n",
      "numero di NaN 0\n",
      "numero di messaggi in file_args 1410\n",
      "numero di channel_id distinte in file_args[1] 180\n",
      "debug count: 2\n",
      "debug count iterations: 284\n",
      "In seguito verra stampato df_english_preprocessed_messages.channel_id.nunique()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|‚ñâ         | 124/1410 [01:20<13:53,  1.54it/s]\n",
      "\n",
      "  0%|          | 1/1410 [00:01<30:18,  1.29s/it]\u001b[A\n",
      "  0%|          | 3/1410 [00:01<13:02,  1.80it/s]\u001b[A\n",
      "  0%|          | 6/1410 [00:02<05:44,  4.08it/s]\u001b[A\n",
      "  1%|          | 8/1410 [00:02<04:03,  5.75it/s]\u001b[A\n",
      "  1%|          | 13/1410 [00:02<02:01, 11.46it/s]\u001b[A\n",
      "  2%|‚ñè         | 33/1410 [00:02<00:34, 39.88it/s]\u001b[A\n",
      "  3%|‚ñé         | 41/1410 [00:02<00:29, 47.02it/s]\u001b[A\n",
      "  4%|‚ñç         | 53/1410 [00:02<00:24, 55.62it/s]\u001b[A\n",
      "  4%|‚ñç         | 61/1410 [00:03<01:14, 18.01it/s]\u001b[A\n",
      "  5%|‚ñç         | 67/1410 [00:04<01:06, 20.06it/s]\u001b[A\n",
      "  5%|‚ñå         | 72/1410 [00:04<01:15, 17.73it/s]\u001b[A\n",
      "  5%|‚ñå         | 76/1410 [00:05<01:50, 12.06it/s]\u001b[A\n",
      "  6%|‚ñå         | 79/1410 [00:05<01:40, 13.25it/s]\u001b[A\n",
      "  6%|‚ñå         | 82/1410 [00:05<02:00, 11.02it/s]\u001b[A\n",
      "  6%|‚ñå         | 86/1410 [00:05<01:42, 12.94it/s]\u001b[A\n",
      "  7%|‚ñã         | 93/1410 [00:06<01:08, 19.29it/s]\u001b[A\n",
      "  7%|‚ñã         | 102/1410 [00:06<00:48, 27.00it/s]\u001b[A\n",
      "  8%|‚ñä         | 107/1410 [00:06<01:12, 17.93it/s]\u001b[A\n",
      "  8%|‚ñä         | 111/1410 [00:07<02:06, 10.27it/s]\u001b[A\n",
      "  8%|‚ñä         | 114/1410 [00:08<02:16,  9.52it/s]\u001b[A\n",
      "  8%|‚ñä         | 116/1410 [00:08<02:14,  9.61it/s]\u001b[A\n",
      "  8%|‚ñä         | 119/1410 [00:08<01:51, 11.58it/s]\u001b[A\n",
      "  9%|‚ñâ         | 125/1410 [00:08<01:15, 17.12it/s]\u001b[A\n",
      "  9%|‚ñâ         | 128/1410 [00:08<01:17, 16.61it/s]\u001b[A\n",
      "  9%|‚ñâ         | 131/1410 [00:08<01:16, 16.78it/s]\u001b[A\n",
      " 10%|‚ñâ         | 137/1410 [00:09<00:53, 23.77it/s]\u001b[A\n",
      " 10%|‚ñà         | 144/1410 [00:09<00:39, 32.23it/s]\u001b[A\n",
      " 11%|‚ñà         | 155/1410 [00:09<00:28, 44.54it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 163/1410 [00:09<00:25, 48.93it/s]\u001b[A\n",
      " 12%|‚ñà‚ñè        | 169/1410 [00:09<00:24, 49.64it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 177/1410 [00:09<00:21, 56.36it/s]\u001b[A\n",
      " 13%|‚ñà‚ñé        | 184/1410 [00:09<00:21, 56.35it/s]\u001b[A\n",
      " 14%|‚ñà‚ñç        | 194/1410 [00:09<00:18, 66.81it/s]\u001b[A\n",
      " 15%|‚ñà‚ñç        | 206/1410 [00:09<00:15, 75.72it/s]\u001b[A\n",
      " 16%|‚ñà‚ñå        | 222/1410 [00:10<00:12, 97.40it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 233/1410 [00:10<00:12, 94.44it/s]\u001b[A\n",
      " 17%|‚ñà‚ñã        | 243/1410 [00:10<00:12, 91.03it/s]\u001b[A\n",
      " 18%|‚ñà‚ñä        | 253/1410 [00:10<00:12, 92.27it/s]\u001b[A\n",
      " 19%|‚ñà‚ñâ        | 269/1410 [00:10<00:10, 108.17it/s]\u001b[A\n",
      " 20%|‚ñà‚ñâ        | 281/1410 [00:10<00:13, 86.27it/s] \u001b[A\n",
      " 21%|‚ñà‚ñà        | 291/1410 [00:10<00:15, 73.44it/s]\u001b[A\n",
      " 21%|‚ñà‚ñà‚ñè       | 300/1410 [00:11<00:15, 70.19it/s]\u001b[A\n",
      " 22%|‚ñà‚ñà‚ñè       | 308/1410 [00:11<00:20, 54.04it/s]\u001b[A\n",
      " 22%|‚ñà‚ñà‚ñè       | 315/1410 [00:11<00:32, 33.62it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 320/1410 [00:12<01:04, 16.89it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 324/1410 [00:13<01:19, 13.73it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 327/1410 [00:13<01:18, 13.80it/s]\u001b[A\n",
      " 23%|‚ñà‚ñà‚ñé       | 331/1410 [00:13<01:09, 15.50it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñé       | 334/1410 [00:13<01:16, 14.15it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 336/1410 [00:14<01:55,  9.31it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 338/1410 [00:14<02:00,  8.91it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 340/1410 [00:15<02:06,  8.43it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 342/1410 [00:15<02:06,  8.42it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 344/1410 [00:15<02:28,  7.18it/s]\u001b[A\n",
      " 24%|‚ñà‚ñà‚ñç       | 345/1410 [00:15<02:44,  6.46it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 347/1410 [00:16<03:33,  4.98it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 348/1410 [00:16<03:21,  5.26it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 349/1410 [00:16<03:03,  5.80it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñç       | 351/1410 [00:16<02:25,  7.26it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 354/1410 [00:17<02:05,  8.45it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 356/1410 [00:17<02:03,  8.53it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 357/1410 [00:17<02:27,  7.16it/s]\u001b[A\n",
      " 25%|‚ñà‚ñà‚ñå       | 359/1410 [00:18<02:49,  6.20it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 360/1410 [00:18<03:40,  4.76it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 361/1410 [00:18<03:46,  4.64it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 365/1410 [00:18<01:59,  8.78it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 367/1410 [00:19<01:40, 10.38it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñå       | 369/1410 [00:19<01:27, 11.85it/s]\u001b[A\n",
      " 26%|‚ñà‚ñà‚ñã       | 371/1410 [00:19<02:02,  8.47it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 375/1410 [00:19<01:21, 12.76it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 377/1410 [00:19<01:22, 12.46it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 379/1410 [00:20<01:27, 11.76it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 383/1410 [00:20<01:01, 16.60it/s]\u001b[A\n",
      " 27%|‚ñà‚ñà‚ñã       | 386/1410 [00:20<01:05, 15.68it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 388/1410 [00:20<01:05, 15.49it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 391/1410 [00:20<00:56, 17.88it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 394/1410 [00:21<01:26, 11.72it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 398/1410 [00:21<01:03, 15.90it/s]\u001b[A\n",
      " 28%|‚ñà‚ñà‚ñä       | 401/1410 [00:21<00:56, 17.80it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñâ       | 407/1410 [00:21<00:39, 25.39it/s]\u001b[A\n",
      " 29%|‚ñà‚ñà‚ñâ       | 412/1410 [00:21<00:33, 29.72it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñâ       | 416/1410 [00:21<00:37, 26.74it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñâ       | 420/1410 [00:22<00:54, 18.16it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñà       | 425/1410 [00:22<00:42, 23.01it/s]\u001b[A\n",
      " 30%|‚ñà‚ñà‚ñà       | 430/1410 [00:22<00:35, 27.62it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà       | 434/1410 [00:22<00:46, 21.01it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà       | 437/1410 [00:22<00:49, 19.47it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 441/1410 [00:23<01:00, 16.13it/s]\u001b[A\n",
      " 31%|‚ñà‚ñà‚ñà‚ñè      | 444/1410 [00:23<01:11, 13.57it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 446/1410 [00:23<01:27, 11.08it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 448/1410 [00:24<01:34, 10.18it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 450/1410 [00:24<01:27, 10.92it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 454/1410 [00:24<01:19, 12.09it/s]\u001b[A\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 457/1410 [00:24<01:16, 12.40it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 460/1410 [00:24<01:07, 13.97it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 462/1410 [00:25<01:13, 12.95it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 465/1410 [00:25<01:08, 13.77it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 467/1410 [00:25<01:09, 13.52it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 469/1410 [00:25<01:34, 10.01it/s]\u001b[A\n",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 471/1410 [00:25<01:38,  9.52it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñé      | 473/1410 [00:26<02:04,  7.51it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 477/1410 [00:26<01:20, 11.55it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 481/1410 [00:27<01:40,  9.21it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 483/1410 [00:27<01:34,  9.83it/s]\u001b[A\n",
      " 34%|‚ñà‚ñà‚ñà‚ñç      | 485/1410 [00:27<01:57,  7.88it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 487/1410 [00:27<01:48,  8.52it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 491/1410 [00:28<02:03,  7.46it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 492/1410 [00:28<02:00,  7.60it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñç      | 493/1410 [00:28<02:09,  7.07it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 495/1410 [00:28<01:48,  8.42it/s]\u001b[A\n",
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 499/1410 [00:29<01:29, 10.20it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 501/1410 [00:29<01:25, 10.59it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 503/1410 [00:29<01:15, 12.08it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 505/1410 [00:29<01:57,  7.69it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 507/1410 [00:30<01:46,  8.48it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 509/1410 [00:30<02:31,  5.93it/s]\u001b[A\n",
      " 36%|‚ñà‚ñà‚ñà‚ñã      | 514/1410 [00:30<01:36,  9.28it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 516/1410 [00:31<01:28, 10.05it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 518/1410 [00:31<01:53,  7.86it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 521/1410 [00:32<02:03,  7.18it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 526/1410 [00:32<01:20, 10.93it/s]\u001b[A\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 528/1410 [00:32<02:01,  7.28it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 530/1410 [00:33<03:01,  4.84it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 532/1410 [00:34<03:34,  4.10it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 535/1410 [00:34<02:59,  4.88it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 537/1410 [00:35<03:28,  4.18it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 540/1410 [00:35<02:48,  5.17it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 541/1410 [00:35<02:36,  5.55it/s]\u001b[A\n",
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 542/1410 [00:36<03:15,  4.44it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñä      | 544/1410 [00:36<03:02,  4.74it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñä      | 545/1410 [00:36<02:56,  4.90it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 547/1410 [00:37<02:16,  6.32it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 549/1410 [00:37<02:26,  5.89it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 550/1410 [00:37<02:19,  6.18it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 551/1410 [00:37<02:21,  6.06it/s]\u001b[A\n",
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 553/1410 [00:38<04:31,  3.16it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñâ      | 562/1410 [00:39<01:35,  8.89it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 564/1410 [00:39<01:54,  7.39it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 566/1410 [00:39<02:02,  6.87it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 568/1410 [00:40<02:03,  6.81it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 569/1410 [00:40<02:09,  6.49it/s]\u001b[A\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 571/1410 [00:40<02:05,  6.71it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 575/1410 [00:40<01:20, 10.40it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 577/1410 [00:41<01:30,  9.22it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 579/1410 [00:41<01:28,  9.44it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 581/1410 [00:41<01:59,  6.93it/s]\u001b[A\n",
      " 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 585/1410 [00:41<01:17, 10.65it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 587/1410 [00:42<01:14, 11.12it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 589/1410 [00:42<02:01,  6.73it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 591/1410 [00:42<01:49,  7.47it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 593/1410 [00:43<01:52,  7.28it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 595/1410 [00:43<01:45,  7.76it/s]\u001b[A\n",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 598/1410 [00:43<01:20, 10.04it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 600/1410 [00:44<02:06,  6.38it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 603/1410 [00:44<01:37,  8.26it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 605/1410 [00:44<01:52,  7.14it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 609/1410 [00:45<01:23,  9.54it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 611/1410 [00:45<01:19, 10.10it/s]\u001b[A\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 613/1410 [00:45<01:31,  8.67it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 615/1410 [00:45<01:32,  8.58it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 616/1410 [00:46<02:18,  5.75it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 619/1410 [00:46<01:33,  8.50it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 623/1410 [00:46<01:09, 11.27it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 625/1410 [00:47<01:58,  6.62it/s]\u001b[A\n",
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 627/1410 [00:47<01:44,  7.46it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 629/1410 [00:47<01:31,  8.51it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 631/1410 [00:47<01:24,  9.24it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 634/1410 [00:48<01:20,  9.61it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 636/1410 [00:48<01:20,  9.56it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 638/1410 [00:48<01:27,  8.87it/s]\u001b[A\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 641/1410 [00:48<01:37,  7.88it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 643/1410 [00:49<01:28,  8.69it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 648/1410 [00:49<01:25,  8.93it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 649/1410 [00:49<01:39,  7.63it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 651/1410 [00:50<01:24,  9.01it/s]\u001b[A\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 653/1410 [00:50<01:48,  6.95it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 658/1410 [00:50<01:04, 11.59it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 660/1410 [00:51<01:33,  8.02it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 662/1410 [00:51<01:46,  7.05it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 665/1410 [00:51<01:35,  7.81it/s]\u001b[A\n",
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 667/1410 [00:52<01:33,  7.97it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 670/1410 [00:52<01:11, 10.35it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 672/1410 [00:52<01:06, 11.07it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 674/1410 [00:52<01:27,  8.43it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 676/1410 [00:52<01:23,  8.78it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 678/1410 [00:53<01:41,  7.22it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 679/1410 [00:53<01:40,  7.28it/s]\u001b[A\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 682/1410 [00:53<01:08, 10.55it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 684/1410 [00:54<01:40,  7.26it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 686/1410 [00:54<01:42,  7.06it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 689/1410 [00:54<01:31,  7.87it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 693/1410 [00:54<01:06, 10.74it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 695/1410 [00:55<01:02, 11.37it/s]\u001b[A\n",
      " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 697/1410 [00:55<01:32,  7.69it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 699/1410 [00:55<01:33,  7.63it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 700/1410 [00:56<01:38,  7.23it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 701/1410 [00:56<01:43,  6.88it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 708/1410 [00:56<00:50, 13.80it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 710/1410 [00:57<01:41,  6.87it/s]\u001b[A\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 712/1410 [00:57<01:35,  7.29it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 714/1410 [00:57<01:49,  6.36it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 715/1410 [00:58<01:59,  5.83it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 716/1410 [00:58<02:17,  5.06it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 717/1410 [00:58<02:48,  4.10it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 718/1410 [00:59<02:33,  4.50it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 719/1410 [00:59<03:12,  3.59it/s]\u001b[A\n",
      " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 722/1410 [01:00<02:35,  4.43it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 730/1410 [01:00<01:02, 10.96it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 732/1410 [01:00<01:18,  8.62it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 734/1410 [01:00<01:21,  8.32it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 736/1410 [01:01<01:11,  9.39it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 738/1410 [01:01<01:03, 10.53it/s]\u001b[A\n",
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 740/1410 [01:01<00:56, 11.85it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 742/1410 [01:01<00:58, 11.45it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 746/1410 [01:01<00:40, 16.38it/s]\u001b[A\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 749/1410 [01:01<00:40, 16.48it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 756/1410 [01:01<00:27, 23.55it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 759/1410 [01:02<00:29, 21.77it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 762/1410 [01:02<00:42, 15.28it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 764/1410 [01:02<00:46, 13.99it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 766/1410 [01:03<01:25,  7.51it/s]\u001b[A\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 768/1410 [01:03<01:25,  7.50it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 770/1410 [01:03<01:19,  8.04it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 772/1410 [01:04<01:30,  7.08it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 774/1410 [01:04<01:44,  6.11it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 777/1410 [01:04<01:20,  7.83it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 780/1410 [01:05<01:05,  9.57it/s]\u001b[A\n",
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 782/1410 [01:05<00:58, 10.81it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 784/1410 [01:05<00:51, 12.26it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 787/1410 [01:05<00:40, 15.20it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 789/1410 [01:05<00:50, 12.38it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 791/1410 [01:05<00:58, 10.55it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 794/1410 [01:06<00:55, 11.20it/s]\u001b[A\n",
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 796/1410 [01:06<00:53, 11.49it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 799/1410 [01:06<00:44, 13.62it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 803/1410 [01:06<00:38, 15.95it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 805/1410 [01:06<00:36, 16.67it/s]\u001b[A\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 809/1410 [01:06<00:30, 19.92it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 812/1410 [01:07<00:29, 19.99it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 817/1410 [01:07<00:23, 25.04it/s]\u001b[A\n",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 823/1410 [01:07<00:19, 30.60it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 831/1410 [01:07<00:15, 38.53it/s]\u001b[A\n",
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 837/1410 [01:07<00:13, 42.02it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 842/1410 [01:07<00:14, 40.04it/s]\u001b[A\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 850/1410 [01:07<00:11, 49.48it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 859/1410 [01:07<00:10, 53.19it/s]\u001b[A\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 865/1410 [01:08<00:11, 47.14it/s]\u001b[A\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 870/1410 [01:08<00:17, 31.55it/s]\u001b[A\n",
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 874/1410 [01:08<00:16, 31.68it/s]\u001b[A\n",
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 896/1410 [01:08<00:07, 68.36it/s]\u001b[A\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 939/1410 [01:08<00:03, 146.40it/s]\u001b[A\n",
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 958/1410 [01:09<00:04, 106.18it/s]\u001b[A\n",
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 974/1410 [01:09<00:05, 79.88it/s] \u001b[A\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 986/1410 [01:09<00:06, 62.30it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 996/1410 [01:10<00:08, 46.22it/s]\u001b[A\n",
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1004/1410 [01:10<00:08, 46.38it/s]\u001b[A\n",
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1018/1410 [01:10<00:06, 57.33it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1026/1410 [01:10<00:08, 44.60it/s]\u001b[A\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 1036/1410 [01:10<00:07, 49.59it/s]\u001b[A\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1043/1410 [01:11<00:08, 44.95it/s]\u001b[A\n",
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1049/1410 [01:11<00:08, 44.16it/s]\u001b[A\n",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1062/1410 [01:11<00:05, 59.45it/s]\u001b[A\n",
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1072/1410 [01:11<00:05, 64.55it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1080/1410 [01:12<00:10, 31.07it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1086/1410 [01:13<00:27, 11.77it/s]\u001b[A\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1091/1410 [01:15<00:39,  8.00it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1094/1410 [01:15<00:40,  7.82it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1097/1410 [01:16<00:40,  7.78it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1099/1410 [01:16<00:37,  8.21it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1101/1410 [01:16<00:35,  8.69it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1103/1410 [01:16<00:33,  9.04it/s]\u001b[A\n",
      " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1106/1410 [01:16<00:26, 11.37it/s]\u001b[A\n",
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1111/1410 [01:16<00:17, 16.63it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 1125/1410 [01:16<00:08, 34.69it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1130/1410 [01:17<00:10, 27.00it/s]\u001b[A\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1134/1410 [01:17<00:12, 22.56it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1138/1410 [01:17<00:12, 22.64it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1141/1410 [01:17<00:14, 18.05it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1144/1410 [01:18<00:14, 18.02it/s]\u001b[A\n",
      " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1147/1410 [01:18<00:13, 19.82it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1150/1410 [01:18<00:17, 14.66it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1153/1410 [01:18<00:16, 15.84it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1156/1410 [01:18<00:14, 17.79it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1159/1410 [01:19<00:15, 15.99it/s]\u001b[A\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1162/1410 [01:19<00:13, 17.97it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1165/1410 [01:19<00:19, 12.63it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1171/1410 [01:19<00:12, 19.35it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1174/1410 [01:20<00:16, 13.92it/s]\u001b[A\n",
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1177/1410 [01:20<00:16, 13.91it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 1179/1410 [01:20<00:17, 13.03it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1181/1410 [01:20<00:20, 11.33it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1185/1410 [01:20<00:15, 14.26it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1187/1410 [01:21<00:20, 10.81it/s]\u001b[A\n",
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1190/1410 [01:21<00:19, 11.44it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1193/1410 [01:21<00:17, 12.52it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 1197/1410 [01:21<00:14, 14.51it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1200/1410 [01:22<00:12, 16.96it/s]\u001b[A\n",
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1202/1410 [01:22<00:13, 15.80it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1206/1410 [01:22<00:10, 19.00it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1209/1410 [01:22<00:10, 19.02it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1212/1410 [01:22<00:13, 14.85it/s]\u001b[A\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 1215/1410 [01:22<00:12, 16.24it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1220/1410 [01:23<00:09, 20.55it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1223/1410 [01:23<00:14, 12.63it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1225/1410 [01:23<00:16, 11.20it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1227/1410 [01:24<00:16, 10.81it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1230/1410 [01:24<00:15, 11.84it/s]\u001b[A\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1232/1410 [01:24<00:19,  9.32it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1234/1410 [01:25<00:22,  7.92it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1235/1410 [01:25<00:21,  8.15it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1237/1410 [01:25<00:17,  9.88it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1240/1410 [01:25<00:12, 13.16it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1242/1410 [01:25<00:13, 12.44it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1244/1410 [01:25<00:13, 12.21it/s]\u001b[A\n",
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1247/1410 [01:25<00:11, 14.23it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1249/1410 [01:25<00:10, 15.32it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 1251/1410 [01:26<00:14, 11.28it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1253/1410 [01:27<00:30,  5.20it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1255/1410 [01:27<00:28,  5.52it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1256/1410 [01:27<00:25,  5.97it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1259/1410 [01:27<00:20,  7.19it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1260/1410 [01:28<00:21,  6.97it/s]\u001b[A\n",
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1261/1410 [01:28<00:21,  6.98it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1264/1410 [01:28<00:22,  6.49it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1265/1410 [01:28<00:22,  6.48it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1266/1410 [01:29<00:26,  5.43it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 1267/1410 [01:29<00:33,  4.28it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1269/1410 [01:29<00:32,  4.40it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1271/1410 [01:30<00:26,  5.29it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1273/1410 [01:30<00:26,  5.12it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1274/1410 [01:31<00:49,  2.76it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1275/1410 [01:31<00:46,  2.88it/s]\u001b[A\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1276/1410 [01:32<01:03,  2.10it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1278/1410 [01:33<00:41,  3.16it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1279/1410 [01:33<00:35,  3.71it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1280/1410 [01:33<00:53,  2.44it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1283/1410 [01:34<00:28,  4.39it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1284/1410 [01:35<00:51,  2.43it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1285/1410 [01:35<00:46,  2.67it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1286/1410 [01:36<00:54,  2.26it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1287/1410 [01:36<01:03,  1.94it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1288/1410 [01:37<00:52,  2.34it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1289/1410 [01:37<00:41,  2.94it/s]\u001b[A\n",
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1290/1410 [01:37<00:32,  3.65it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1292/1410 [01:37<00:26,  4.38it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1293/1410 [01:38<00:42,  2.77it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1294/1410 [01:38<00:41,  2.77it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1295/1410 [01:39<00:37,  3.09it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1296/1410 [01:39<00:37,  3.07it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1297/1410 [01:39<00:35,  3.18it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1298/1410 [01:39<00:29,  3.76it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1299/1410 [01:39<00:26,  4.18it/s]\u001b[A\n",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 1304/1410 [01:40<00:10, 10.59it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1309/1410 [01:40<00:06, 14.67it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1312/1410 [01:40<00:05, 16.82it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1315/1410 [01:40<00:05, 16.34it/s]\u001b[A\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 1318/1410 [01:40<00:05, 18.35it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1323/1410 [01:40<00:03, 24.79it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1326/1410 [01:41<00:04, 18.53it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1329/1410 [01:41<00:03, 20.57it/s]\u001b[A\n",
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1332/1410 [01:41<00:03, 22.22it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1335/1410 [01:41<00:03, 22.76it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 1338/1410 [01:41<00:03, 23.50it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1341/1410 [01:41<00:03, 20.08it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1344/1410 [01:42<00:09,  7.24it/s]\u001b[A\n",
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1346/1410 [01:43<00:11,  5.71it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1349/1410 [01:43<00:08,  7.15it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1351/1410 [01:43<00:07,  8.12it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1353/1410 [01:44<00:07,  7.59it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1355/1410 [01:44<00:09,  5.59it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 1357/1410 [01:45<00:12,  4.38it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1358/1410 [01:45<00:11,  4.66it/s]\u001b[A\n",
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1360/1410 [01:45<00:09,  5.54it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1361/1410 [01:45<00:08,  5.69it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1362/1410 [01:46<00:10,  4.63it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1363/1410 [01:46<00:09,  4.85it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1364/1410 [01:47<00:18,  2.50it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1367/1410 [01:47<00:10,  4.19it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1369/1410 [01:48<00:14,  2.90it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1370/1410 [01:48<00:12,  3.33it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1371/1410 [01:49<00:13,  2.79it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1372/1410 [01:49<00:14,  2.69it/s]\u001b[A\n",
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 1374/1410 [01:50<00:09,  3.97it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1375/1410 [01:50<00:09,  3.72it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1376/1410 [01:50<00:08,  3.95it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1377/1410 [01:51<00:14,  2.25it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1378/1410 [01:53<00:25,  1.26it/s]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1379/1410 [01:56<00:45,  1.45s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1380/1410 [01:59<00:58,  1.97s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1381/1410 [02:01<00:52,  1.80s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1382/1410 [02:04<00:58,  2.09s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1383/1410 [02:04<00:41,  1.53s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1384/1410 [02:07<00:57,  2.19s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1385/1410 [02:14<01:28,  3.53s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1386/1410 [02:22<01:52,  4.69s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1387/1410 [02:22<01:18,  3.42s/it]\u001b[A\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1388/1410 [02:23<01:01,  2.81s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1389/1410 [02:25<00:49,  2.38s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1390/1410 [02:28<00:52,  2.64s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1391/1410 [02:31<00:49,  2.62s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 1392/1410 [02:36<01:02,  3.46s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1393/1410 [02:38<00:49,  2.90s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1394/1410 [02:39<00:41,  2.58s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1395/1410 [02:46<00:58,  3.91s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1396/1410 [02:47<00:41,  2.94s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1397/1410 [02:53<00:50,  3.86s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1398/1410 [02:53<00:33,  2.81s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1399/1410 [03:01<00:46,  4.19s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1400/1410 [03:11<01:00,  6.04s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1401/1410 [03:25<01:16,  8.47s/it]\u001b[A\n",
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1402/1410 [03:37<01:15,  9.43s/it]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1403/1410 [03:43<00:59,  8.46s/it]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1404/1410 [03:50<00:47,  7.90s/it]\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1405/1410 [04:49<01:56, 23.20s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-----An entry of ~/telegram_2024/usc-tg-24-us-election/extracted/channel_2144322933/2024-03.tsv.gz\n",
    "   id       user_id text   timestamp  bot_flag  via_bot_id  \\\n",
    "0   5  6.897729e+09  Hii  1711518674       NaN         NaN   \n",
    "\n",
    "   via_business_bot_id  reply_to_msg_id  fwd_flag  fwd_from_id media_type  \\\n",
    "0                  NaN              NaN       NaN          NaN        NaN   \n",
    "\n",
    "   views  forwards  replies  reactions reaction_json  \n",
    "0    NaN       NaN        0          0           NaN\n",
    "\n",
    "\n",
    "üìå Tabelle nel DB: [('chats',)]\n",
    "‚úÖ chats.db - Tabella 'chats'\n",
    "  type_and_id                            token parent     timestamp\n",
    "0        None           [keyword] thedemocrats   None  1.722583e+09\n",
    "1        None  [keyword] makeamericagreatagain   None  1.722583e+09\n",
    "2        None                   [keyword] MAGA   None  1.722583e+09\n",
    "3        None            [keyword] Nikki Haley   None  1.722583e+09\n",
    "4        None  [keyword] Robert F. Kennedy Jr.   None  1.722583e+09\n",
    "‚úÖ discovery_edges.csv.gz, \n",
    "Il timestamp da l'ultima volta che hanno visitato quel gruppo ma questo significa che non √® davvero indicativo di una timeline \n",
    "\n",
    "          type_and_id              parent     timestamp\n",
    "0  channel_1306559115  channel_1840578235  1.722586e+09\n",
    "1  channel_2036850729  channel_1840578235  1.722586e+09\n",
    "2  channel_1941222046  channel_1840578235  1.722586e+09\n",
    "3  channel_1749991917  channel_1840578235  1.722586e+09\n",
    "4  channel_1581117699  channel_1840578235  1.722586e+09\n",
    "‚úÖ first_nodes.csv.gz\n",
    "          type_and_id                    token                      parent\n",
    "0  channel_2036421633               trump2024e         [keyword] Trump2024\n",
    "1  channel_2178554925  biden_has_left_the_chat             [keyword] Biden\n",
    "2  channel_2095394414             speech_biden      [keyword] Joseph Biden\n",
    "3  channel_2202860593       republicanpartyeth  [keyword] Republican party\n",
    "4  channel_2157448164      republican_partysol  [keyword] Republican party\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Percorso del file finale gi√† preprocessato\n",
    "output_path = \"../material/english_preprocessed_messages.tsv.gz\"\n",
    "\n",
    "# Se il file esiste, lo carica direttamente e salta tutto il resto\n",
    "if os.path.exists(output_path):\n",
    "    print(f\"‚úÖ File gi√† esistente: {output_path}. Carico direttamente.\")\n",
    "    df_english_preprocessed_messages = pd.read_csv(output_path, sep='\\t', compression='gzip')\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages.drop_duplicates(subset=['text_preprocessed'])\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages.dropna()\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages.astype(str)\n",
    "    valid = df_english_preprocessed_messages[\"text_preprocessed\"].map(lambda x: isinstance(x, str))\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages[valid]\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages[df_english_preprocessed_messages['text_preprocessed'].apply(lambda x: isinstance(x, str))]\n",
    "    print(f\"‚úîÔ∏è  File caricato con {len(df_english_preprocessed_messages)} messaggi pre-processati.\")\n",
    "else:\n",
    "    print(f\"üõ†Ô∏è  File non trovato, procedo con il preprocessing...\")\n",
    "\n",
    "    def process_file(args):\n",
    "        file, channel_id, token = args\n",
    "        try:\n",
    "            df = pd.read_csv(file, sep='\\t', compression='gzip', usecols=['text','timestamp'])\n",
    "            df = df.dropna(subset=['text'])\n",
    "            df['text'] = df['text'].astype(str)\n",
    "            df['text_preprocessed'] = df['text'].apply(preprocess_text)\n",
    "            df = df[df['text_preprocessed']!=\"\"]\n",
    "            df['channel_id'] = channel_id\n",
    "            df['token'] = token\n",
    "            return df if not df.empty else None\n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Errore nel file {file}: {e}')\n",
    "            return None\n",
    "\n",
    "    debug_count = 0\n",
    "    debug_count_iterations = 0\n",
    "    file_args = []\n",
    "\n",
    "    channels_without_message = []\n",
    "    counter_channels_without_message = 0\n",
    "    for _, row in df_first_nodes.iterrows():\n",
    "        debug_count_iterations += 1\n",
    "        channel_id = row['type_and_id']\n",
    "        token = row['token']\n",
    "        channel_path = os.path.join(extracted_dir, channel_id)\n",
    "        if not os.path.isdir(channel_path):\n",
    "            debug_count += 1\n",
    "            continue\n",
    "        files = glob(os.path.join(channel_path, '[0-9][0-9][0-9][0-9]-[0-1][0-9].tsv.gz'))\n",
    "        \n",
    "        if not files:\n",
    "            counter_channels_without_message+=1\n",
    "            channels_without_message.append(channel_id)\n",
    "            continue\n",
    "        \n",
    "        file_args.extend([(file, channel_id, token) for file in files])\n",
    "\n",
    "    print(\"len(df_first_nodes)\", len(df_first_nodes))\n",
    "    print(\"print(df_first_nodes.type_and_id.nunique())\", df_first_nodes.type_and_id.nunique())\n",
    "    print(\"numero di NaN\", str(sum(pd.isna(entry[1]) for entry in file_args)))\n",
    "    print(\"numero di messaggi in file_args\", len(file_args))\n",
    "    print(\"numero di channel_id distinte in file_args[1]\", len({entry[1] for entry in file_args}))\n",
    "    print(\"debug count:\", debug_count)\n",
    "    print(\"debug count iterations:\", debug_count_iterations)\n",
    "    print(\"In seguito verra stampato df_english_preprocessed_messages.channel_id.nunique()\")\n",
    "\n",
    "    # Multiprocessing\n",
    "    results = []\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        pbar = tqdm(total=len(file_args))\n",
    "        for res in pool.imap_unordered(process_file, file_args):\n",
    "            pbar.update(1)\n",
    "            results.append(res)\n",
    "\n",
    "    all_english_messages = [df for df in results if df is not None]\n",
    "    df_english_preprocessed_messages = pd.concat(all_english_messages, ignore_index=True)\n",
    "    print(\"----df_english_preprocessed_messages prima di drop_duplicates\", df_english_preprocessed_messages.channel_id.nunique())\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages.drop_duplicates(subset=['text_preprocessed'])\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages.dropna()\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages.astype(str)\n",
    "    valid = df_english_preprocessed_messages[\"text_preprocessed\"].map(lambda x: isinstance(x, str))\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages[valid]\n",
    "    df_english_preprocessed_messages.to_csv(output_path, sep='\\t', index=False, compression='gzip')\n",
    "    print(df_english_preprocessed_messages.head(10))\n",
    "    df_english_preprocessed_messages = df_english_preprocessed_messages[\n",
    "    df_english_preprocessed_messages['text_preprocessed'].apply(lambda x: isinstance(x, str))\n",
    "    ]\n",
    "\n",
    "df_english_preprocessed_messages['date'] = pd.to_datetime(\n",
    "    df_english_preprocessed_messages['timestamp'],\n",
    "    unit='s'\n",
    ")\n",
    "\n",
    "print(f\"debug a row with df_english_preprocessed_messages.head(1) {df_english_preprocessed_messages.head(1)} \")\n",
    "print(f\"# of channels ids without messages in channels_without_message (len(channels_without_message)){len(channels_without_message)}\")\n",
    "print(f\"counter_channels_without_message: {counter_channels_without_message}\")\n",
    "print(f\"# of unique channels ids without messages in channels_without_message (len(set(channels_without_message))){len(set(channels_without_message))}\")\n",
    "\n",
    "print(f\"channels without messages {channels_without_message}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98fd5d1-2d40-4a7b-aab5-37a3c11c5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 3Ô∏è‚É£ Istogramma di tutte le date dei messaggi\n",
    "df_english_preprocessed_messages['date'].hist(bins=120)\n",
    "plt.title(\"üìÖ Tutti i messaggi pre-processati\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Numero di messaggi\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4Ô∏è‚É£ Numero di testi pre-processati\n",
    "print(\"Numero di testi pre-processati:\", len(df_english_preprocessed_messages['text_preprocessed']))\n",
    "\n",
    "# 5Ô∏è‚É£ Numero di canali unici\n",
    "print(\"---\")\n",
    "print(\"Numero di canali unici:\", df_english_preprocessed_messages['channel_id'].nunique())\n",
    "print(\"---\")\n",
    "\n",
    "# 6Ô∏è‚É£ Istogramma della data dell‚Äôultimo messaggio per ciascun canale\n",
    "df_english_preprocessed_messages.sort_values(by='date') \\\n",
    "    .drop_duplicates(subset='channel_id', keep='last')['date'] \\\n",
    "    .hist(bins=100)\n",
    "plt.title(\"üìÖ Ultima data di messaggio per ciascun canale\")\n",
    "plt.xlabel(\"Data\")\n",
    "plt.ylabel(\"Numero di canali\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd8049-f9ef-4edd-97f4-7ee210cca814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model_name = 'all-distilroberta-v1'\n",
    "embedding_model=SentenceTransformer(model_name)\n",
    "\n",
    "if os.path.exists(f'../final/final_embeddings_{model_name}.npy'):\n",
    "    print('file found')\n",
    "    embeddings = np.load(f'../final/final_embeddings_{model_name}.npy')\n",
    "    print(f'embedding {model_name} loaded')\n",
    "else:\n",
    "    embedding_model = embedding_model.to(device)\n",
    "    embeddings = embedding_model.encode(df_english_preprocessed_messages['text_preprocessed'].tolist(), show_progress_bar=True, device=device)\n",
    "    np.save(f'../final/final_embeddings_{model_name}.npy', embeddings)\n",
    "\n",
    "print(f\"df_english_preprocessed_messages['text_preprocessed'].tolist(): {df_english_preprocessed_messages['text_preprocessed'].tolist()}\")\n",
    "print(f\"embeddings: {embeddings}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342381c-933b-46de-9181-fbd3e95d4b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "umap_params = {'n_components': 5, 'n_neighbors': 5, 'min_dist': 0.0}\n",
    "hdbscan_params = {'min_cluster_size': 500,'min_samples':100,'prediction_data':True}\n",
    "\n",
    "output_path = f'../final/final_{model_name}.pkl'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    print(f\"debug {len(df_english_preprocessed_messages)} messaggi pre-processati.\")\n",
    "\n",
    "    umap_model = UMAP(**umap_params)\n",
    "    hdbscan_model = HDBSCAN(**hdbscan_params)\n",
    "\n",
    "    max_features_vectorizer = 1024\n",
    "    min_df_vectorizer = 0.01\n",
    "    max_df_vectorizer = 0.99 \n",
    "\n",
    "    vectorizer_model = CountVectorizer(\n",
    "        max_features=max_features_vectorizer, \n",
    "        min_df=min_df_vectorizer,\n",
    "        max_df=max_df_vectorizer\n",
    "    )\n",
    "\n",
    "    print(\"embeddings.shape\", embeddings.shape)\n",
    "\n",
    "    t0 = time.time()\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=None,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        verbose=True,\n",
    "        top_n_words=20,\n",
    "        language='english', \n",
    "        vectorizer_model=vectorizer_model\n",
    "    )\n",
    "\n",
    "    print(\"embedding shape 0\" + str(embeddings.shape[0]))\n",
    "    print(\"embedding first\", embeddings[0])\n",
    "    print(\"len df \"+ str(len(df_english_preprocessed_messages['text_preprocessed'])))\n",
    "    assert embeddings.shape[0] == len(df_english_preprocessed_messages['text_preprocessed'])\n",
    "\n",
    "    topics, probs = topic_model.fit_transform(df_english_preprocessed_messages['text_preprocessed'], embeddings=embeddings)\n",
    "    print(f\"Execution time for {model_name} UMAP: {time.time()-t0}s\")\n",
    "\n",
    "    topics = np.array(topics)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    topic_model.save(output_path)\n",
    "else:\n",
    "    print(f\"Model already saved at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08c2cd-c974-430c-9b05-010b5a938544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_model=BERTopic.load(f'../final/final_{model_name}.pkl')\n",
    "topics=np.array(topic_model.topics_)\n",
    "\n",
    "topic_model.visualize_barchart(top_n_topics=-1,n_words=20, width = 350,height=450)\n",
    "\n",
    "#top_n_topics=-1\tMostra tutti i topic (eccetto outlier -1)\ttop_n_topics=5 mostrerebbe solo i primi 5 topic pi√π grandi\n",
    "#n_words=20\tMostra 20 parole per ogni topic nel grafico\tSe vuoi vederne solo 10, metti n_words=10\n",
    "#width=350\tLarghezza (in pixel) del grafico\tCambia la dimensione orizzontale del plot\n",
    "#height=450\tAltezza (in pixel) del grafico\tCambia la dimensione verticale del plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832737dc-03ef-4603-9060-3f9fe1c8e1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = df_english_preprocessed_messages['text_preprocessed']\n",
    "timestamps = pd.to_datetime(df_english_preprocessed_messages['date'],format=\"%Y-%m-%d\")\n",
    "\n",
    "topics_over_time = topic_model.topics_over_time(\n",
    "    list(df_english_preprocessed_messages['text_preprocessed']),\n",
    "    list(df_english_preprocessed_messages['date']),\n",
    "    nr_bins = timestamps.nunique(),\n",
    "    global_tuning = False,\n",
    "    evolution_tuning = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a204319-726a-4322-a17a-f7a0914cd573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = topic_model.visualize_topics_over_time(\n",
    "    topics_over_time,\n",
    "    top_n_topics=5\n",
    ")\n",
    "\n",
    "distinct_colors = px.colors.qualitative.Alphabet\n",
    "\n",
    "for i, trace in enumerate(fig.data):\n",
    "    if i < len(distinct_colors):\n",
    "        trace.line.color = distinct_colors[i]\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f9fcb-ee0f-4dfa-9c80-aed2d92ed0a1",
   "metadata": {},
   "source": [
    "- reduce outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3be546-0e58-42a4-906e-bb80a8b0d88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "umap_model=topic_model.umap_model\n",
    "reduced_embeddings=umap_model.transform(embeddings)\n",
    "\n",
    "new_topics = topic_model.reduce_outliers(list(texts), topics , strategy=\"c-tf-idf\", threshold=0.1)\n",
    "\n",
    "#Quando BERTopic prova a riassegnare un outlier, confronta il suo contenuto testuale con i topic usando una misura di similarit√† tra vettori TF-IDF.\n",
    "#Di solito si tratta di una similarit√† coseno, che varia tra:\n",
    "#0.0 = nessuna somiglianza\n",
    "#1.0 = perfetta somiglianza\n",
    "#0.1 √® molto poco\n",
    "\n",
    "\n",
    "\n",
    "topic_model.update_topics(list(texts), topics=new_topics,\n",
    "                          vectorizer_model=vectorizer_model,top_n_words=20)\n",
    "topic_model.get_topic_info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1024c9-7f2a-44a6-9517-31d0c220b8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_topics=np.array(new_topics)\n",
    "pd.Series(new_topics).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adcd337-a7ac-4f44-9572-5055aee64b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5122a-76a1-4dac-8589-7788e4f11657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b1620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2eaf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419220d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7529d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe23eca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59f818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535cab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd8dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda:bertopic_env",
   "language": "python",
   "name": "bertopic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
